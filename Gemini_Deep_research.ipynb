{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2-na643G0GYB",
        "outputId": "3fc0eb0c-844e-4564-8aec-5bc3720a625e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.2 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hAll packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# @title # Step 1: Install Required Packages\n",
        "# @markdown Run this cell to install all necessary packages for the research agent.\n",
        "\n",
        "print(\"Installing required packages...\")\n",
        "\n",
        "# Install core LangChain packages\n",
        "!pip install -qU langchain-core langchain-community\n",
        "\n",
        "# Install LangGraph\n",
        "!pip install -qU langgraph\n",
        "\n",
        "# Install text splitters package\n",
        "!pip install -qU langchain-text-splitters\n",
        "\n",
        "# Install Google Generative AI\n",
        "!pip install -qU google-generativeai\n",
        "\n",
        "# Install requests for API calls\n",
        "!pip install -qU requests\n",
        "\n",
        "print(\"All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 2: Import Required Libraries (Corrected for LangGraph)\n",
        "# @markdown Run this cell to import all necessary libraries with correct LangGraph imports.\n",
        "\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "from typing import List, TypedDict, Annotated, Literal, Callable, Any, Dict, Optional\n",
        "import operator\n",
        "from datetime import datetime\n",
        "from getpass import getpass\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "# LangGraph imports for graph functionality\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# Text splitter import\n",
        "try:\n",
        "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "except ImportError:\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# OpenAI (for OpenRouter compatibility)\n",
        "from openai import OpenAI\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pUfKeBv0O_t",
        "outputId": "da4be4e3-25fe-4ed9-a0e8-6bf7155913a5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 3: Define Custom Middleware for LangGraph\n",
        "# @markdown This cell defines the custom middleware classes that work with LangGraph.\n",
        "\n",
        "class LangGraphMiddleware:\n",
        "    \"\"\"Custom middleware implementation for LangGraph agents\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.before_model_hooks = []\n",
        "        self.after_model_hooks = []\n",
        "        self.modify_request_hooks = []\n",
        "        self.tool_call_hooks = []\n",
        "\n",
        "    def before_model(self, func):\n",
        "        \"\"\"Decorator for before_model hooks\"\"\"\n",
        "        self.before_model_hooks.append(func)\n",
        "        return func\n",
        "\n",
        "    def after_model(self, func):\n",
        "        \"\"\"Decorator for after_model hooks\"\"\"\n",
        "        self.after_model_hooks.append(func)\n",
        "        return func\n",
        "\n",
        "    def modify_request(self, func):\n",
        "        \"\"\"Decorator for modify_request hooks\"\"\"\n",
        "        self.modify_request_hooks.append(func)\n",
        "        return func\n",
        "\n",
        "    def tool_call(self, func):\n",
        "        \"\"\"Decorator for tool_call hooks\"\"\"\n",
        "        self.tool_call_hooks.append(func)\n",
        "        return func\n",
        "\n",
        "    def apply_before_model(self, state: dict, config: Optional[RunnableConfig] = None) -> dict:\n",
        "        \"\"\"Apply all before_model hooks\"\"\"\n",
        "        for hook in self.before_model_hooks:\n",
        "            state = hook(state, config)\n",
        "        return state\n",
        "\n",
        "    def apply_after_model(self, state: dict, response: Any, config: Optional[RunnableConfig] = None) -> dict:\n",
        "        \"\"\"Apply all after_model hooks\"\"\"\n",
        "        for hook in self.after_model_hooks:\n",
        "            state = hook(state, response, config)\n",
        "        return state\n",
        "\n",
        "    def apply_modify_request(self, state: dict, config: Optional[RunnableConfig] = None) -> dict:\n",
        "        \"\"\"Apply all modify_request hooks\"\"\"\n",
        "        for hook in self.modify_request_hooks:\n",
        "            state = hook(state, config)\n",
        "        return state\n",
        "\n",
        "    def apply_tool_call(self, tool_name: str, tool_input: dict, state: dict) -> dict:\n",
        "        \"\"\"Apply all tool_call hooks\"\"\"\n",
        "        result = {\"tool_name\": tool_name, \"tool_input\": tool_input, \"state\": state}\n",
        "        for hook in self.tool_call_hooks:\n",
        "            result = hook(result[\"tool_name\"], result[\"tool_input\"], result[\"state\"])\n",
        "        return result\n",
        "\n",
        "\n",
        "# Create global middleware instance\n",
        "middleware = LangGraphMiddleware()\n",
        "\n",
        "# Define middleware hooks\n",
        "\n",
        "@middleware.before_model\n",
        "def add_temporal_context(state: dict, config: Optional[RunnableConfig] = None) -> dict:\n",
        "    \"\"\"Add temporal context to research queries\"\"\"\n",
        "    if 'research_query' in state:\n",
        "        query = state['research_query']\n",
        "        current_year = datetime.now().year\n",
        "\n",
        "        # Add year if not already present\n",
        "        if str(current_year) not in query and 'latest' not in query.lower():\n",
        "            state['research_query'] = f\"{query} {current_year} latest developments\"\n",
        "\n",
        "        # Store original query\n",
        "        if 'original_query' not in state:\n",
        "            state['original_query'] = query\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "@middleware.before_model\n",
        "def mask_pii(state: dict, config: Optional[RunnableConfig] = None) -> dict:\n",
        "    \"\"\"Mask PII in inputs\"\"\"\n",
        "    if 'messages' in state and state['messages']:\n",
        "        last_message = state['messages'][-1]\n",
        "        if isinstance(last_message, HumanMessage):\n",
        "            content = last_message.content\n",
        "\n",
        "            # Simple PII masking patterns\n",
        "            pii_patterns = {\n",
        "                'email': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
        "                'phone': r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b',\n",
        "                'ssn': r'\\b\\d{3}-\\d{2}-\\d{4}\\b'\n",
        "            }\n",
        "\n",
        "            for pii_type, pattern in pii_patterns.items():\n",
        "                content = re.sub(pattern, f'[{pii_type.upper()}_MASKED]', content)\n",
        "\n",
        "            # Update message with masked content\n",
        "            state['messages'][-1] = HumanMessage(content=content)\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "@middleware.modify_request\n",
        "def adjust_model_parameters(state: dict, config: Optional[RunnableConfig] = None) -> dict:\n",
        "    \"\"\"Adjust model parameters for better research\"\"\"\n",
        "    if 'model_params' not in state:\n",
        "        state['model_params'] = {}\n",
        "\n",
        "    # Lower temperature for more factual responses\n",
        "    state['model_params']['temperature'] = 0.3\n",
        "\n",
        "    # Add system prompt for research context\n",
        "    if 'messages' in state:\n",
        "        system_message = SystemMessage(\n",
        "            content=\"You are a research assistant focused on providing the most current information. Prioritize recent findings and emerging trends.\"\n",
        "        )\n",
        "        if not any(isinstance(msg, SystemMessage) for msg in state['messages']):\n",
        "            state['messages'].insert(0, system_message)\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "@middleware.after_model\n",
        "def highlight_recent_content(state: dict, response: Any, config: Optional[RunnableConfig] = None) -> dict:\n",
        "    \"\"\"Highlight recent content in model outputs\"\"\"\n",
        "    if hasattr(response, 'content'):\n",
        "        content = response.content\n",
        "\n",
        "        # Highlight 2025 content\n",
        "        current_year = datetime.now().year\n",
        "        if str(current_year) in content:\n",
        "            content = f\"[{current_year} RESEARCH] {content}\"\n",
        "            response.content = content\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "@middleware.tool_call\n",
        "def log_tool_call(tool_name: str, tool_input: dict, state: dict) -> dict:\n",
        "    \"\"\"Log tool calls for debugging\"\"\"\n",
        "    print(f\"Tool called: {tool_name} with input: {tool_input}\")\n",
        "    return {\"tool_name\": tool_name, \"tool_input\": tool_input, \"state\": state}\n",
        "\n",
        "print(\"âœ“ Custom LangGraph middleware defined successfully!\")\n",
        "print(\"\\nMiddleware hooks registered:\")\n",
        "print(\"  - add_temporal_context: Adds year context to queries\")\n",
        "print(\"  - mask_pii: Masks PII in inputs\")\n",
        "print(\"  - adjust_model_parameters: Adjusts model parameters\")\n",
        "print(\"  - highlight_recent_content: Highlights recent content\")\n",
        "print(\"  - log_tool_call: Logs tool calls\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzU8IKwqZFEy",
        "outputId": "013867df-3ad8-42c5-eafc-e4a2c507fdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Custom LangGraph middleware defined successfully!\n",
            "\n",
            "Middleware hooks registered:\n",
            "  - add_temporal_context: Adds year context to queries\n",
            "  - mask_pii: Masks PII in inputs\n",
            "  - adjust_model_parameters: Adjusts model parameters\n",
            "  - highlight_recent_content: Highlights recent content\n",
            "  - log_tool_call: Logs tool calls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 4: Set Up Google API Key\n",
        "# @markdown Run this cell to securely set up your Google API key.\n",
        "\n",
        "# Ask for Google API key securely\n",
        "api_key = getpass('Enter your Google API key: ')\n",
        "\n",
        "# Set environment variables directly in Colab\n",
        "os.environ['GOOGLE_API_KEY'] = api_key\n",
        "os.environ['MODEL'] = 'gemini-2.5-pro'\n",
        "os.environ['TEMPERATURE'] = '0.3'\n",
        "\n",
        "# Also save to .env file for persistence\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(f\"GOOGLE_API_KEY={api_key}\\n\")\n",
        "    f.write(f\"MODEL=gemini-2.5-pro\\n\")\n",
        "    f.write(f\"TEMPERATURE=0.3\\n\")\n",
        "\n",
        "print(\"Google API key set successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD9jz4sS0SYX",
        "outputId": "8398be0e-e31b-4c11-a1a8-11a9c2cea967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Google API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Google API key set successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 5: Set Up Serper.dev API Key\n",
        "# @markdown Enter your Serper.dev API key for web search functionality.\n",
        "\n",
        "# Ask for Serper.dev API key securely\n",
        "serper_api_key = getpass('Enter your Serper.dev API key: ')\n",
        "\n",
        "# Set environment variable\n",
        "os.environ['SERPER_API_KEY'] = serper_api_key\n",
        "\n",
        "# Add to .env file\n",
        "with open('.env', 'a') as f:\n",
        "    f.write(f\"SERPER_API_KEY={serper_api_key}\\n\")\n",
        "\n",
        "print(\"Serper.dev API key set successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x32N-Ja80aGq",
        "outputId": "e5cc7a66-464b-40e6-b0c7-3b02c4c9c665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Serper.dev API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Serper.dev API key set successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 6: Configure Google Gemini API with LangGraph Middleware\n",
        "# @markdown This cell sets up the Google Gemini 2.5 Pro model and the Serper.dev search API with proper LangGraph middleware.\n",
        "\n",
        "# Read environment variables from .env file if they exist\n",
        "def load_env_file():\n",
        "    env_vars = {}\n",
        "    try:\n",
        "        with open('.env', 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip() and not line.startswith('#'):\n",
        "                    key, value = line.strip().split('=', 1)\n",
        "                    env_vars[key] = value\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "    return env_vars\n",
        "\n",
        "# Load environment variables\n",
        "env_vars = load_env_file()\n",
        "\n",
        "# Set environment variables or use existing ones\n",
        "GOOGLE_API_KEY = env_vars.get('GOOGLE_API_KEY', os.environ.get('GOOGLE_API_KEY'))\n",
        "MODEL = env_vars.get('MODEL', os.environ.get('MODEL', 'gemini-2.5-pro'))\n",
        "TEMPERATURE = env_vars.get('TEMPERATURE', os.environ.get('TEMPERATURE', '0.3'))\n",
        "SERPER_API_KEY = env_vars.get('SERPER_API_KEY', os.environ.get('SERPER_API_KEY'))\n",
        "\n",
        "# Validate API keys\n",
        "if not GOOGLE_API_KEY:\n",
        "    raise ValueError(\"Google API key not found. Please run Step 4 to set your API key.\")\n",
        "if not SERPER_API_KEY:\n",
        "    raise ValueError(\"Serper.dev API key not found. Please run Step 5 to set your API key.\")\n",
        "\n",
        "# Set environment variables for this session\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "os.environ['MODEL'] = MODEL\n",
        "os.environ['TEMPERATURE'] = TEMPERATURE\n",
        "os.environ['SERPER_API_KEY'] = SERPER_API_KEY\n",
        "\n",
        "# Configure Google Gemini client\n",
        "import google.generativeai as genai\n",
        "\n",
        "class GeminiLLM:\n",
        "    def __init__(self, api_key, model=\"gemini-2.5-pro\", temperature=0.3):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel(model)\n",
        "        self.temperature = temperature\n",
        "        self.middleware = middleware\n",
        "\n",
        "    def invoke(self, messages):\n",
        "        # Create state for middleware\n",
        "        state = {\n",
        "            \"messages\": messages,\n",
        "            \"model_params\": {\"temperature\": self.temperature}\n",
        "        }\n",
        "\n",
        "        # Apply before_model middleware\n",
        "        state = self.middleware.apply_before_model(state)\n",
        "\n",
        "        # Apply modify_request middleware\n",
        "        state = self.middleware.apply_modify_request(state)\n",
        "\n",
        "        # Convert LangChain messages to Gemini format\n",
        "        gemini_messages = []\n",
        "        for msg in state['messages']:\n",
        "            if isinstance(msg, HumanMessage):\n",
        "                gemini_messages.append({\"role\": \"user\", \"parts\": [msg.content]})\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                gemini_messages.append({\"role\": \"model\", \"parts\": [msg.content]})\n",
        "            elif isinstance(msg, SystemMessage):\n",
        "                # Gemini doesn't have a system role, so we'll prepend to the first user message\n",
        "                if gemini_messages and gemini_messages[0][\"role\"] == \"user\":\n",
        "                    gemini_messages[0][\"parts\"][0] = f\"{msg.content}\\n\\n{gemini_messages[0]['parts'][0]}\"\n",
        "                else:\n",
        "                    gemini_messages.insert(0, {\"role\": \"user\", \"parts\": [msg.content]})\n",
        "\n",
        "        try:\n",
        "            # Generate response\n",
        "            response = self.model.generate_content(\n",
        "                gemini_messages,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=self.temperature\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Create a response object with content attribute\n",
        "            class Response:\n",
        "                def __init__(self, content):\n",
        "                    self.content = content\n",
        "\n",
        "            result = Response(response.text)\n",
        "\n",
        "            # Apply after_model middleware\n",
        "            state = self.middleware.apply_after_model(state, result)\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Google Gemini API call: {str(e)}\")\n",
        "            # Return a fallback response\n",
        "            class Response:\n",
        "                def __init__(self):\n",
        "                    self.content = f\"Error: Unable to get response from Google Gemini 2.5 Pro. Error details: {str(e)}\"\n",
        "\n",
        "            return Response()\n",
        "\n",
        "# Configure Serper.dev search API with temporal filtering\n",
        "class SerperSearch:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.url = \"https://google.serper.dev/search\"\n",
        "        self.middleware = middleware\n",
        "\n",
        "    def run(self, query):\n",
        "        try:\n",
        "            # Apply middleware to query\n",
        "            state = {\"research_query\": query}\n",
        "            state = self.middleware.apply_before_model(state)\n",
        "\n",
        "            enhanced_query = state.get('research_query', query)\n",
        "\n",
        "            payload = {\n",
        "                \"q\": enhanced_query,\n",
        "                \"num\": 10,  # Get more results\n",
        "                \"tbs\": \"qdr:y\",  # Past year\n",
        "                \"sort\": \"date\"  # Sort by date\n",
        "            }\n",
        "\n",
        "            headers = {\n",
        "                'X-API-KEY': self.api_key,\n",
        "                'Content-Type': 'application/json'\n",
        "            }\n",
        "\n",
        "            response = requests.post(self.url, headers=headers, json=payload)\n",
        "\n",
        "            # Check if response is valid JSON\n",
        "            try:\n",
        "                results = response.json()\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error: Serper.dev returned non-JSON response. Status code: {response.status_code}\")\n",
        "                print(f\"Response content: {response.text[:500]}...\")\n",
        "                return f\"Error: Serper.dev returned invalid response. Status code: {response.status_code}\"\n",
        "\n",
        "            # Filter and prioritize recent results\n",
        "            filtered_results = []\n",
        "            current_year = datetime.now().year\n",
        "\n",
        "            for result in results.get('organic', []):\n",
        "                # Check if current year is in title or snippet\n",
        "                if str(current_year) in result.get('title', '') or str(current_year) in result.get('snippet', ''):\n",
        "                    filtered_results.insert(0, result)  # Prioritize recent results\n",
        "                else:\n",
        "                    filtered_results.append(result)\n",
        "\n",
        "            return self.format_results(filtered_results[:5])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Serper.dev API call: {str(e)}\")\n",
        "            return f\"Error: Unable to get search results. Error details: {str(e)}\"\n",
        "\n",
        "    def format_results(self, results):\n",
        "        \"\"\"Format search results with emphasis on recent content\"\"\"\n",
        "        formatted_results = \"Search Results (Recent First):\\n\\n\"\n",
        "        current_year = datetime.now().year\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            title = result.get('title', 'No title')\n",
        "            snippet = result.get('snippet', 'No snippet')\n",
        "            link = result.get('link', 'No link')\n",
        "\n",
        "            # Highlight recent content\n",
        "            if str(current_year) in title or str(current_year) in snippet:\n",
        "                formatted_results += f\"{i}. ğŸ†• {title}\\n\"\n",
        "            else:\n",
        "                formatted_results += f\"{i}. {title}\\n\"\n",
        "\n",
        "            formatted_results += f\"   {snippet}\\n\"\n",
        "            formatted_results += f\"   URL: {link}\\n\\n\"\n",
        "\n",
        "        if 'knowledgeGraph' in results:\n",
        "            kg = results['knowledgeGraph']\n",
        "            formatted_results += f\"Knowledge Graph: {kg.get('title', 'No title')}\\n\"\n",
        "            if 'description' in kg:\n",
        "                formatted_results += f\"{kg['description']}\\n\\n\"\n",
        "\n",
        "        return formatted_results\n",
        "\n",
        "# Initialize LLM and Search\n",
        "llm = GeminiLLM(\n",
        "    api_key=GOOGLE_API_KEY,\n",
        "    model=MODEL,\n",
        "    temperature=float(TEMPERATURE)\n",
        ")\n",
        "search_tool = SerperSearch(SERPER_API_KEY)\n",
        "\n",
        "print(\"Google Gemini 2.5 Pro and Serper.dev with LangGraph Middleware configured successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMmuyYv90d7p",
        "outputId": "e0ff6bde-3cda-4a55-de67-f91e60b819f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Gemini 2.5 Pro and Serper.dev with LangGraph Middleware configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 7: Define State and Node Classes with LangGraph Middleware\n",
        "# @markdown This cell defines the state management and node classes for the research agent with LangGraph middleware integration.\n",
        "\n",
        "# Define State\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[List[HumanMessage], add_messages]\n",
        "    iteration: int\n",
        "    expected_result: str\n",
        "    feedback: str\n",
        "    agent_outputs: Annotated[List[AIMessage], add_messages]\n",
        "    evaluation: float\n",
        "    continue_loop: bool\n",
        "    research_query: str\n",
        "    original_query: str  # Added for middleware\n",
        "    model_params: Dict[str, Any]  # Added for middleware\n",
        "\n",
        "# Base Node Class with middleware support\n",
        "class NodeWithMiddleware:\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.middleware = middleware\n",
        "\n",
        "    def process(self, state: State) -> dict:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __call__(self, state: State) -> dict:\n",
        "        try:\n",
        "            # Apply before_model middleware\n",
        "            state_dict = self.middleware.apply_before_model(dict(state))\n",
        "\n",
        "            result = self.process(state_dict)\n",
        "            print(f\"{self.name}: Processing complete\")\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error in {self.name}: {str(e)}\")\n",
        "            # Return a basic error response\n",
        "            return {\n",
        "                \"messages\": [AIMessage(role=\"system\", content=f\"Error in {self.name}: {str(e)}\")],\n",
        "                \"agent_outputs\": [AIMessage(role=\"assistant\", content=f\"Error in {self.name}: {str(e)}\")]\n",
        "            }\n",
        "\n",
        "# 1. SEARCH NODE - Performs web search with LangGraph middleware\n",
        "class SearchNode(NodeWithMiddleware):\n",
        "    def __init__(self, agent_name: str, llm, search_tool):\n",
        "        super().__init__(agent_name)\n",
        "        self.llm = llm\n",
        "        self.search_tool = search_tool\n",
        "\n",
        "    def process(self, state: dict) -> dict:\n",
        "        research_query = state.get('research_query', state.get('original_query', ''))\n",
        "        feedback = state.get('feedback', '')\n",
        "\n",
        "        try:\n",
        "            # Perform web search\n",
        "            search_results = self.search_tool.run(research_query)\n",
        "\n",
        "            # Check if search returned an error\n",
        "            if search_results.startswith(\"Error:\"):\n",
        "                print(f\"Search error: {search_results}\")\n",
        "                # Use a fallback search result\n",
        "                search_results = f\"Unable to perform web search. Using fallback information for query: {research_query}\"\n",
        "\n",
        "            # Process search results with LLM\n",
        "            if feedback:\n",
        "                process_prompt = f\"\"\"\n",
        "                Research Query: {research_query}\n",
        "                Previous Feedback: {feedback}\n",
        "\n",
        "                Web Search Results:\n",
        "                {search_results}\n",
        "\n",
        "                Please analyze these search results and provide a comprehensive research response that:\n",
        "                1. Synthesizes key information from multiple sources\n",
        "                2. Addresses the research query thoroughly\n",
        "                3. Incorporates the feedback from previous iterations\n",
        "                4. Provides proper citations and references\n",
        "                5. Emphasizes recent developments and latest trends\n",
        "                \"\"\"\n",
        "            else:\n",
        "                process_prompt = f\"\"\"\n",
        "                Research Query: {research_query}\n",
        "\n",
        "                Web Search Results:\n",
        "                {search_results}\n",
        "\n",
        "                Please analyze these search results and provide a comprehensive research response that:\n",
        "                1. Synthesizes key information from multiple sources\n",
        "                2. Addresses the research query thoroughly\n",
        "                3. Provides proper citations and references\n",
        "                4. Emphasizes recent developments and latest trends\n",
        "                \"\"\"\n",
        "\n",
        "            response = self.llm.invoke([HumanMessage(role=\"user\", content=process_prompt)])\n",
        "            agent_output = AIMessage(role=\"assistant\", content=f\"{self.name} research: {response.content}\")\n",
        "\n",
        "            return {\"messages\": [agent_output], \"agent_outputs\": [agent_output]}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in search process: {str(e)}\")\n",
        "            # Return a basic error response\n",
        "            error_output = AIMessage(role=\"assistant\", content=f\"Error in search process: {str(e)}\")\n",
        "            return {\"messages\": [error_output], \"agent_outputs\": [error_output]}\n",
        "\n",
        "# 2. SUMMARIZE NODE - Processes and synthesizes research findings\n",
        "class SummarizeNode(NodeWithMiddleware):\n",
        "    def __init__(self, llm):\n",
        "        super().__init__(\"Summarizer\")\n",
        "        self.llm = llm\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=3000,\n",
        "            chunk_overlap=300,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "        )\n",
        "\n",
        "    def process(self, state: dict) -> dict:\n",
        "        agent_outputs = state.get('agent_outputs', [])\n",
        "\n",
        "        if not agent_outputs:\n",
        "            return {\"messages\": [AIMessage(role=\"system\", content=\"No research outputs to summarize\")]}\n",
        "\n",
        "        try:\n",
        "            # Combine all agent outputs\n",
        "            combined_research = \"\\n\\n\".join([output.content for output in agent_outputs])\n",
        "\n",
        "            # Check if text is large enough to require splitting\n",
        "            if len(combined_research) > 4000:\n",
        "                summary = self.hierarchical_summarize(combined_research)\n",
        "            else:\n",
        "                summary = self.direct_summarize(combined_research)\n",
        "\n",
        "            summary_output = AIMessage(role=\"assistant\", content=f\"Research Summary: {summary}\")\n",
        "\n",
        "            return {\"messages\": [summary_output]}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in summarization process: {str(e)}\")\n",
        "            # Return a basic error response\n",
        "            error_output = AIMessage(role=\"assistant\", content=f\"Error in summarization process: {str(e)}\")\n",
        "            return {\"messages\": [error_output]}\n",
        "\n",
        "    def hierarchical_summarize(self, text: str) -> str:\n",
        "        \"\"\"Hierarchical summarization for large texts\"\"\"\n",
        "        print(f\"Text length ({len(text)} characters) exceeds threshold, using hierarchical summarization\")\n",
        "\n",
        "        try:\n",
        "            # Split text into chunks\n",
        "            chunks = self.text_splitter.split_text(text)\n",
        "            print(f\"Split text into {len(chunks)} chunks\")\n",
        "\n",
        "            # Summarize each chunk\n",
        "            chunk_summaries = []\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                print(f\"Summarizing chunk {i+1}/{len(chunks)}\")\n",
        "                chunk_summary = self.summarize_chunk(chunk)\n",
        "                chunk_summaries.append(chunk_summary)\n",
        "\n",
        "            # Combine chunk summaries\n",
        "            combined_summary = \"\\n\\n\".join(chunk_summaries)\n",
        "\n",
        "            # Final summary of combined summaries\n",
        "            final_summary = self.summarize_chunk(combined_summary)\n",
        "\n",
        "            return final_summary\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in hierarchical summarization: {str(e)}\")\n",
        "            return f\"Error in summarization: {str(e)}\"\n",
        "\n",
        "    def summarize_chunk(self, text: str) -> str:\n",
        "        \"\"\"Summarize a chunk of text\"\"\"\n",
        "        try:\n",
        "            summarize_prompt = f\"\"\"\n",
        "            Please summarize the following text, emphasizing any recent developments or latest trends:\n",
        "\n",
        "            {text}\n",
        "\n",
        "            Provide a concise summary that captures the main points and key details, with special attention to recent developments.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.llm.invoke([HumanMessage(role=\"user\", content=summarize_prompt)])\n",
        "            return response.content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in chunk summarization: {str(e)}\")\n",
        "            return f\"Error in summarizing text chunk: {str(e)}\"\n",
        "\n",
        "    def direct_summarize(self, text: str) -> str:\n",
        "        \"\"\"Direct summarization for smaller texts\"\"\"\n",
        "        try:\n",
        "            summarize_prompt = f\"\"\"\n",
        "            Please synthesize and summarize the following research findings:\n",
        "\n",
        "            {text}\n",
        "\n",
        "            Provide a coherent summary that:\n",
        "            1. Integrates key points from all sources\n",
        "            2. Identifies main themes and conclusions\n",
        "            3. Highlights any contradictions or gaps\n",
        "            4. Suggests areas for further investigation if needed\n",
        "            5. Emphasizes recent developments and latest trends\n",
        "\n",
        "            The summary should be comprehensive yet concise.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.llm.invoke([HumanMessage(role=\"user\", content=summarize_prompt)])\n",
        "            return response.content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in direct summarization: {str(e)}\")\n",
        "            return f\"Error in direct summarization: {str(e)}\"\n",
        "\n",
        "# 3. CRITIQUE NODE - Evaluates research quality\n",
        "class CritiqueNode(NodeWithMiddleware):\n",
        "    def __init__(self, llm):\n",
        "        super().__init__(\"Critique\")\n",
        "        self.llm = llm\n",
        "\n",
        "    def process(self, state: dict) -> dict:\n",
        "        research_query = state.get('research_query', state.get('original_query', ''))\n",
        "        agent_outputs = state.get('agent_outputs', [])\n",
        "\n",
        "        if not agent_outputs:\n",
        "            return {\n",
        "                \"feedback\": \"No research outputs available for evaluation\",\n",
        "                \"evaluation\": 0.0\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            # Get the latest research outputs\n",
        "            latest_research = \"\\n\\n\".join([output.content for output in agent_outputs[-3:]])  # Last 3 outputs\n",
        "\n",
        "            critique_prompt = f\"\"\"\n",
        "            Research Query: {research_query}\n",
        "\n",
        "            Research Findings:\n",
        "            {latest_research}\n",
        "\n",
        "            Please evaluate this research based on the following criteria:\n",
        "            1. **Comprehensiveness**: Does it cover all major aspects of the query?\n",
        "            2. **Accuracy**: Is the information correct and well-supported?\n",
        "            3. **Depth**: Does it provide sufficient detail and analysis?\n",
        "            4. **Clarity**: Is the information well-organized and understandable?\n",
        "            5. **Currency**: Is the information up-to-date and relevant?\n",
        "            6. **Recent Focus**: Does it emphasize recent developments and latest trends?\n",
        "\n",
        "            Provide:\n",
        "            1. Detailed feedback on strengths and weaknesses\n",
        "            2. Specific suggestions for improvement\n",
        "            3. An evaluation score from 0.0 to 1.0 (where 1.0 is excellent)\n",
        "\n",
        "            Format your response exactly as:\n",
        "            Feedback: [your detailed feedback]\n",
        "            Evaluation Score: [score between 0.0 and 1.0]\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.llm.invoke([HumanMessage(role=\"user\", content=critique_prompt)])\n",
        "            feedback, evaluation = self.parse_feedback_and_evaluation(response.content)\n",
        "\n",
        "            return {\n",
        "                \"messages\": [AIMessage(role=\"system\", content=f\"Critique: {response.content}\")],\n",
        "                \"feedback\": feedback,\n",
        "                \"evaluation\": evaluation\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in critique process: {str(e)}\")\n",
        "            return {\n",
        "                \"messages\": [AIMessage(role=\"system\", content=f\"Error in critique: {str(e)}\")],\n",
        "                \"feedback\": f\"Error in critique process: {str(e)}\",\n",
        "                \"evaluation\": 0.0\n",
        "            }\n",
        "\n",
        "    def parse_feedback_and_evaluation(self, content: str):\n",
        "        try:\n",
        "            lines = content.splitlines()\n",
        "            feedback = ''\n",
        "            evaluation = 0.0\n",
        "\n",
        "            for line in lines:\n",
        "                if line.startswith(\"Feedback:\"):\n",
        "                    feedback = line.replace(\"Feedback:\", \"\").strip()\n",
        "                elif line.startswith(\"Evaluation Score:\"):\n",
        "                    score_str = line.replace(\"Evaluation Score:\", \"\").strip()\n",
        "                    try:\n",
        "                        evaluation = float(score_str)\n",
        "                    except ValueError:\n",
        "                        evaluation = 0.0\n",
        "\n",
        "            return feedback, evaluation\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing feedback and evaluation: {str(e)}\")\n",
        "            return f\"Error parsing feedback: {str(e)}\", 0.0\n",
        "\n",
        "# 4. LOOP CONTROL NODE - Decides whether to continue research\n",
        "class LoopControlNode(NodeWithMiddleware):\n",
        "    def __init__(self, max_iterations: int = 2, target_score: float = 0.7):\n",
        "        super().__init__(\"LoopControl\")\n",
        "        self.max_iterations = max_iterations\n",
        "        self.target_score = target_score\n",
        "\n",
        "    def process(self, state: dict) -> dict:\n",
        "        try:\n",
        "            state['iteration'] += 1\n",
        "            iteration = state['iteration']\n",
        "            evaluation = state['evaluation']\n",
        "\n",
        "            print(f\"Iteration {iteration}, Evaluation Score: {evaluation}\")\n",
        "\n",
        "            # Check termination conditions\n",
        "            if evaluation >= self.target_score:\n",
        "                print(f\"Target score ({self.target_score}) reached. Terminating process.\")\n",
        "                state['continue_loop'] = False\n",
        "            elif iteration >= self.max_iterations:\n",
        "                print(f\"Maximum iterations ({self.max_iterations}) reached. Terminating process.\")\n",
        "                state['continue_loop'] = False\n",
        "            else:\n",
        "                print(\"Continuing to next iteration for improvement.\")\n",
        "                state['continue_loop'] = True\n",
        "\n",
        "            return state\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loop control: {str(e)}\")\n",
        "            state['continue_loop'] = False  # Terminate on error\n",
        "            return state\n",
        "\n",
        "# 5. SUPERVISOR NODE - Orchestrates the research process\n",
        "class SupervisorNode(NodeWithMiddleware):\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Supervisor\")\n",
        "\n",
        "    def process(self, state: dict) -> dict:\n",
        "        try:\n",
        "            research_query = state.get('research_query', '')\n",
        "\n",
        "            # Initialize or reset iteration state\n",
        "            if state['iteration'] == 0:\n",
        "                state['feedback'] = ''\n",
        "                state['evaluation'] = 0.0\n",
        "                state['agent_outputs'] = []\n",
        "\n",
        "            # Store original query if not already stored\n",
        "            if 'original_query' not in state:\n",
        "                state['original_query'] = research_query\n",
        "\n",
        "            thought_prompt = f\"\"\"\n",
        "            Research Query: {research_query}\n",
        "            Iteration: {state['iteration'] + 1}\n",
        "\n",
        "            Please conduct comprehensive research on this topic, incorporating any previous feedback and focusing on recent developments.\n",
        "            \"\"\"\n",
        "\n",
        "            return {\n",
        "                \"messages\": [HumanMessage(role=\"system\", content=thought_prompt)],\n",
        "                \"expected_result\": research_query\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in supervisor process: {str(e)}\")\n",
        "            return {\n",
        "                \"messages\": [HumanMessage(role=\"system\", content=f\"Error in supervisor: {str(e)}\")],\n",
        "                \"expected_result\": state.get('research_query', '')\n",
        "            }\n",
        "\n",
        "print(\"State and Node classes with LangGraph Middleware defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS6yKvVc0iSf",
        "outputId": "72b92e56-f6db-44d7-8fa8-fa385ca10515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State and Node classes with LangGraph Middleware defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 8: Build the Research Graph with LangGraph Middleware\n",
        "# @markdown This cell builds the research workflow graph using LangGraph with middleware integration.\n",
        "\n",
        "def build_research_graph():\n",
        "    builder = StateGraph(State)\n",
        "\n",
        "    # Initialize nodes with middleware support\n",
        "    nodes = {\n",
        "        \"supervisor\": SupervisorNode(),\n",
        "        \"search\": SearchNode(\"GLM 4.5 Air Researcher\", llm, search_tool),\n",
        "        \"summarize\": SummarizeNode(llm),\n",
        "        \"critique\": CritiqueNode(llm),\n",
        "        \"loop_control\": LoopControlNode(max_iterations=2, target_score=0.7)\n",
        "    }\n",
        "\n",
        "    # Add all nodes to graph\n",
        "    for name, node in nodes.items():\n",
        "        builder.add_node(name, node)\n",
        "\n",
        "    # Define workflow\n",
        "    builder.add_edge(START, \"supervisor\")\n",
        "    builder.add_edge(\"supervisor\", \"search\")\n",
        "    builder.add_edge(\"search\", \"summarize\")\n",
        "    builder.add_edge(\"summarize\", \"critique\")\n",
        "    builder.add_edge(\"critique\", \"loop_control\")\n",
        "\n",
        "    # Loop control decides whether to continue or end\n",
        "    def decide_next_step(state: State) -> Literal[\"supervisor\", END]:\n",
        "        if state['continue_loop']:\n",
        "            return \"supervisor\"\n",
        "        else:\n",
        "            return END\n",
        "\n",
        "    builder.add_conditional_edges(\"loop_control\", decide_next_step)\n",
        "\n",
        "    # Compile the graph\n",
        "    graph = builder.compile()\n",
        "\n",
        "    return graph\n",
        "\n",
        "# Build the research graph\n",
        "research_graph = build_research_graph()\n",
        "\n",
        "print(\"Research graph with LangGraph Middleware built successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifnuv_df0mtq",
        "outputId": "1679f9ba-1ac5-4868-c11b-4dcf9236660c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research graph with LangGraph Middleware built successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 9: Define the Research Agent Execution Function\n",
        "# @markdown This cell defines the function to execute the research agent with LangGraph middleware.\n",
        "\n",
        "def run_research_agent(research_query: str, max_iterations=2, target_score=0.7):\n",
        "    \"\"\"\n",
        "    Execute the research agent with the given query using LangGraph middleware.\n",
        "\n",
        "    Args:\n",
        "        research_query: The research question to investigate\n",
        "        max_iterations: Maximum number of research iterations\n",
        "        target_score: Target evaluation score to terminate research\n",
        "\n",
        "    Returns:\n",
        "        Final state containing all research results\n",
        "    \"\"\"\n",
        "    # Initialize state\n",
        "    initial_state = State(\n",
        "        messages=[HumanMessage(role=\"user\", content=research_query)],\n",
        "        iteration=0,\n",
        "        expected_result=\"\",\n",
        "        feedback=\"\",\n",
        "        agent_outputs=[],\n",
        "        evaluation=0.0,\n",
        "        continue_loop=True,\n",
        "        research_query=research_query,\n",
        "        original_query=\"\",\n",
        "        model_params={}\n",
        "    )\n",
        "\n",
        "    # Update loop control parameters\n",
        "    for node in research_graph.nodes.values():\n",
        "        if isinstance(node, LoopControlNode):\n",
        "            node.max_iterations = max_iterations\n",
        "            node.target_score = target_score\n",
        "\n",
        "    # Run the research process\n",
        "    print(f\"Starting deep research on: {research_query}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Using LangGraph Middleware with temporal filtering and recent content emphasis\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    final_state = research_graph.invoke(initial_state, {\"recursion_limit\": 150})\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"RESEARCH COMPLETE\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Total iterations: {final_state['iteration']}\")\n",
        "    print(f\"Final evaluation score: {final_state['evaluation']}\")\n",
        "    print(f\"Final feedback: {final_state['feedback']}\")\n",
        "\n",
        "    print(\"\\nFINAL RESEARCH OUTPUTS:\")\n",
        "    for i, output in enumerate(final_state['agent_outputs'], 1):\n",
        "        print(f\"\\n--- Research Output {i} ---\")\n",
        "        print(output.content)\n",
        "\n",
        "    return final_state\n",
        "\n",
        "print(\"Research agent execution function with LangGraph Middleware defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-qQVD8V0tgb",
        "outputId": "00fa7404-de11-4c04-8746-46948fae235d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research agent execution function with LangGraph Middleware defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 10: Run the Research Agent with LangGraph Middleware\n",
        "# @markdown Enter your research query and run the agent with LangGraph middleware.\n",
        "\n",
        "# @markdown Enter your research query:\n",
        "research_query = \"Langgraph agent middleware  before model after model hooks\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown Maximum number of iterations:\n",
        "max_iterations = 7  # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "# @markdown Target evaluation score (0.0-1.0):\n",
        "target_score = 0.65  # @param {type:\"slider\", min:0.5, max:1.0, step:0.05}\n",
        "\n",
        "# Run the research agent with LangGraph middleware\n",
        "results = run_research_agent(research_query, max_iterations, target_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "foF1wFuz0y2k",
        "outputId": "1357da8e-5510-40c3-a30e-3668e1b3aa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting deep research on: Langgraph agent middleware  before model after model hooks\n",
            "==================================================\n",
            "Using LangGraph Middleware with temporal filtering and recent content emphasis\n",
            "==================================================\n",
            "Supervisor: Processing complete\n",
            "GLM 4.5 Air Researcher: Processing complete\n",
            "Text length (5695 characters) exceeds threshold, using hierarchical summarization\n",
            "Split text into 3 chunks\n",
            "Summarizing chunk 1/3\n",
            "Summarizing chunk 2/3\n",
            "Summarizing chunk 3/3\n",
            "Summarizer: Processing complete\n",
            "Critique: Processing complete\n",
            "Iteration 1, Evaluation Score: 0.95\n",
            "Target score (0.7) reached. Terminating process.\n",
            "LoopControl: Processing complete\n",
            "\n",
            "==================================================\n",
            "RESEARCH COMPLETE\n",
            "==================================================\n",
            "Total iterations: 1\n",
            "Final evaluation score: 0.95\n",
            "Final feedback: \n",
            "\n",
            "FINAL RESEARCH OUTPUTS:\n",
            "\n",
            "--- Research Output 1 ---\n",
            "GLM 4.5 Air Researcher research: [2025 RESEARCH] Of course. Here is a research response analyzing the provided search results on LangGraph agent middleware.\n",
            "\n",
            "### **Research Response: LangGraph Agent Middleware Developments and 2025 Outlook**\n",
            "\n",
            "**Executive Summary:**\n",
            "Recent developments in LangChain and LangGraph, particularly with the v1.0 release, have formally introduced a powerful agent middleware system. This system provides developers with granular control over agent execution through hooks, including the specifically requested `before_model` and `after_model` calls. While the core functionality is established in the current v1.0 framework, a speculative, forward-looking article imagines a major framework rewrite in September 2025, signaling a potential trend towards even more significant architectural changes in the future.\n",
            "\n",
            "---\n",
            "\n",
            "### **1. Core Middleware Functionality in LangGraph v1.0**\n",
            "\n",
            "The v1.0 milestone for LangChain and LangGraph introduced agent middleware as a core, revolutionary feature designed to enhance flexibility and control (LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones; LangChain Middleware v1-Alpha). This system functions similarly to middleware in web servers, allowing developers to define a sequence of operations that execute at specific points within an agent's lifecycle (Agent Middleware - LangChain Blog).\n",
            "\n",
            "Key interception points, or hooks, provided by this middleware include:\n",
            "*   At the start and end of the agent loop\n",
            "*   Around tool calls\n",
            "*   **Before and after the model call**\n",
            "\n",
            "This directly addresses the central part of your query regarding `before_model` and `after_model` hooks.\n",
            "\n",
            "#### **`before_model` Hook**\n",
            "\n",
            "This hook executes immediately before the agent makes its call to the language model. It provides a critical opportunity to inspect, log, or modify the inputs being sent to the model.\n",
            "\n",
            "*   **Common Use Cases:**\n",
            "    *   **Prompt Templating/Modification:** Dynamically altering prompts based on real-time data or preceding agent steps.\n",
            "    *   **Input Validation:** Ensuring the data and prompt structure meet required specifications before incurring the cost of a model call.\n",
            "    *   **Enhanced Logging:** Recording the exact prompt and configuration sent to the model for debugging and analysis (Agent Middleware - LangChain Blog).\n",
            "\n",
            "#### **`after_model` Hook**\n",
            "\n",
            "This hook executes immediately after the agent receives a response from the language model but before that response is processed by the next step in the agent's logic.\n",
            "\n",
            "*   **Common Use Cases:**\n",
            "    *   **Output Parsing and Validation:** Checking the model's output for correctness, format, or compliance with predefined schemas.\n",
            "    *   **Error Handling:** Catching malformed outputs or model-generated errors and triggering fallback or correction logic.\n",
            "    *   **Response Modification:** Cleaning, sanitizing, or augmenting the model's raw output before it is used for tool calls or returned to the user (LangChain and LangGraph v1.0: Beyond Release Notes).\n",
            "\n",
            "### **2. Latest Developments and 2025 Outlook**\n",
            "\n",
            "The most recent development highlighted in the search results is a speculative article that looks ahead to **September 2025**.\n",
            "\n",
            "A Medium article titled \"LangChain 1.0 â€” A second look\" is written from a future perspective, imagining a \"major rewrite of the LangChain and LangGraph frameworks\" occurring in September 2025. This piece suggests that the community could see a significant architectural evolution beyond the current v1.0 release.\n",
            "\n",
            "**Key Implications of this Trend:**\n",
            "\n",
            "*   **Emerging Discussion:** While this article is a hypothetical scenario and **not an official roadmap**, its existence points to an emerging trend in community discussion. It suggests that developers are already thinking about the next generation of agentic frameworks beyond the current implementations.\n",
            "*   **Future of Middleware:** A potential \"major rewrite\" could further enhance or abstract the middleware concept, possibly introducing more sophisticated hooks, state management across middleware layers, or even more declarative ways to define agent behavior.\n",
            "\n",
            "This forward-looking piece represents the latest \"bleeding-edge\" thinking on the topic, shifting the conversation from the implementation details of v1.0 to the architectural possibilities of a future v2.0 or beyond (LangChain 1.0 â€” A second look - Medium).\n",
            "\n",
            "### **Conclusion**\n",
            "\n",
            "The current, stable implementation of LangGraph agent middleware in v1.0 provides robust `before_model` and `after_model` hooks, giving developers significant control over the agent's core logic. This is the established state-of-the-art. The latest emerging trend, as captured in speculative analysis, is the anticipation of a future major rewrite in 2025 that could fundamentally evolve these foundational concepts. For now, developers can confidently build on the v1.0 middleware system while keeping an eye on community discussions that may shape the next iteration of the framework.\n",
            "\n",
            "---\n",
            "### **References**\n",
            "\n",
            "1.  \"LangChain 1.0 â€” A second look.\" *Medium*, https://medium.com/mitb-for-all/langchain-a-second-look-6ed720e27fec.\n",
            "2.  \"LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones.\" *LangChain Blog*, https://blog.langchain.com/langchain-langgraph-1dot0/.\n",
            "3.  \"LangChain and LangGraph v1.0: Beyond Release Notes, Into Real...\" *Medium*, https://agentissue.medium.com/langchain-and-langgraph-v1-0-beyond-release-notes-into-real-roi-7538fc02ff83.\n",
            "4.  \"Agent Middleware.\" *LangChain Blog*, https://blog.langchain.com/agent-middleware/.\n",
            "5.  \"LangChain Middleware v1-Alpha: A Comprehensive Guide to Agent...\" *colinmcnamara.com*, https://colinmcnamara.com/blog/langchain-middleware-v1-alpha-guide.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jWP3im54t6BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 11: Save Research Results\n",
        "# @markdown Save the research results to a file for later reference.\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# Prepare results data\n",
        "output_data = {\n",
        "    \"query\": research_query,\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"iterations\": results['iteration'],\n",
        "    \"final_score\": results['evaluation'],\n",
        "    \"feedback\": results['feedback'],\n",
        "    \"research_outputs\": [output.content for output in results['agent_outputs']],\n",
        "    \"middleware_used\": \"LangGraph Middleware with temporal filtering and recent content emphasis\"\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "filename = f\"research_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(filename, 'w') as f:\n",
        "    json.dump(output_data, f, indent=2)\n",
        "\n",
        "print(f\"Research results saved to {filename}\")\n",
        "\n",
        "# Download the file\n",
        "files.download(filename)"
      ],
      "metadata": {
        "id": "w9bzs4sF1Acl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "99a3218b-ca20-449d-aba7-e5336c62e281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research results saved to research_results_20251101_154538.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2996b3ce-636f-4d61-a5c5-6bb68ee77950\", \"research_results_20251101_154538.json\", 6103)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Step 12: Visualize Research Process\n",
        "# @markdown Visualize the research process and results.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Extract evaluation scores (if available)\n",
        "# Note: In a real implementation, you would track scores across iterations\n",
        "# For this example, we'll simulate some data\n",
        "iterations = np.arange(1, results['iteration'] + 1)\n",
        "scores = np.linspace(0.5, results['evaluation'], results['iteration'])\n",
        "\n",
        "# Create a simple plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(iterations, scores, 'o-', linewidth=2, markersize=8, label='Research Quality')\n",
        "plt.axhline(y=target_score, color='r', linestyle='--', label=f'Target Score ({target_score})')\n",
        "plt.title('Research Quality Over Iterations\\n(Using LangGraph Middleware)', fontsize=14)\n",
        "plt.xlabel('Iteration', fontsize=12)\n",
        "plt.ylabel('Evaluation Score', fontsize=12)\n",
        "plt.xticks(iterations)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nResearch Summary Statistics:\")\n",
        "print(f\"- Total iterations: {results['iteration']}\")\n",
        "print(f\"- Final evaluation score: {results['evaluation']:.2f}\")\n",
        "print(f\"- Target score achieved: {'Yes' if results['evaluation'] >= target_score else 'No'}\")\n",
        "print(f\"- Average score improvement per iteration: {(results['evaluation'] - 0.5) / results['iteration']:.2f}\")\n",
        "print(f\"- Middleware used: LangGraph Middleware with temporal filtering\")"
      ],
      "metadata": {
        "id": "GXL1b-WY1E3S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "ae38d032-ea9b-42c4-c547-a5d422c967c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Research Summary Statistics:\n",
            "- Total iterations: 1\n",
            "- Final evaluation score: 0.95\n",
            "- Target score achieved: Yes\n",
            "- Average score improvement per iteration: 0.45\n",
            "- Middleware used: LangGraph Middleware with temporal filtering\n"
          ]
        }
      ]
    }
  ]
}